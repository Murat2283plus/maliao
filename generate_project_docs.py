
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é¡¹ç›®ä»£ç æ–‡æ¡£ç”Ÿæˆå™¨
ç”¨äºç”ŸæˆåŒ…å«é¡¹ç›®ç»“æ„å’Œæ‰€æœ‰ä»£ç å†…å®¹çš„Markdownæ–‡æ¡£
è·¯å¾„: /home/mulati/Murat_large/sda/è€å¸ˆçš„é¡¹ç›®/é…åˆå‰ç«¯ä»£ç /generate_project_docs.py
"""

import os
import sys
from datetime import datetime
from pathlib import Path

# è¿è¡Œç»ˆç«¯å‘½ä»¤

shell_code = '''#!/bin/bash

# ç›®å½•è·¯å¾„
TARGET_DIR="./"

# è¾“å‡ºæ–‡ä»¶å
OUTPUT_FILE="directory_report.md"

# Python è„šæœ¬å†…å®¹
python3 << 'EOF'
import os
import sys
from collections import defaultdict, Counter
from pathlib import Path
import re
from datetime import datetime

def get_file_extension(filename):
    """è·å–æ–‡ä»¶æ‰©å±•å"""
    return Path(filename).suffix.lower()

def get_file_size_str(size_bytes):
    """å°†å­—èŠ‚æ•°è½¬æ¢ä¸ºå¯è¯»æ ¼å¼"""
    if size_bytes < 1024:
        return f"{size_bytes}B"
    elif size_bytes < 1024**2:
        return f"{size_bytes/1024:.1f}KB"
    elif size_bytes < 1024**3:
        return f"{size_bytes/(1024**2):.1f}MB"
    else:
        return f"{size_bytes/(1024**3):.1f}GB"

def get_directory_signature(path, max_sample_size=10):
    """è·å–ç›®å½•çš„ç‰¹å¾ç­¾åï¼Œç”¨äºè¯†åˆ«ç›¸ä¼¼ç›®å½•ç»“æ„"""
    try:
        items = os.listdir(path)
        subdirs = []
        files_by_ext = defaultdict(int)
        
        for item in items[:max_sample_size]:  # åªé‡‡æ ·å‰å‡ ä¸ªé¡¹ç›®
            item_path = os.path.join(path, item)
            if os.path.isdir(item_path):
                subdirs.append("DIR")
            elif os.path.isfile(item_path):
                ext = get_file_extension(item)
                files_by_ext[ext] += 1
        
        # ç”Ÿæˆç­¾åï¼šå­ç›®å½•æ•°é‡ + æ–‡ä»¶ç±»å‹åŠå¤§è‡´æ•°é‡
        signature = f"dirs:{len(subdirs)}|files:{dict(sorted(files_by_ext.items()))}"
        return signature
    except:
        return "ERROR"

def find_similar_directories(parent_path, max_show=3):
    """æŸ¥æ‰¾ç›¸ä¼¼çš„ç›®å½•å¹¶åˆ†ç»„"""
    try:
        dirs = [d for d in os.listdir(parent_path) 
                if os.path.isdir(os.path.join(parent_path, d))]
    except:
        return {}
    
    if len(dirs) <= max_show:
        return {d: [d] for d in dirs}
    
    # æŒ‰ç›®å½•ç­¾ååˆ†ç»„
    signature_groups = defaultdict(list)
    for directory in dirs:
        dir_path = os.path.join(parent_path, directory)
        signature = get_directory_signature(dir_path)
        signature_groups[signature].append(directory)
    
    # å¤„ç†åˆ†ç»„ç»“æœ
    result = {}
    for signature, dir_group in signature_groups.items():
        if len(dir_group) <= max_show:
            # å¦‚æœç»„å†…ç›®å½•æ•°é‡ä¸å¤šï¼Œå•ç‹¬æ˜¾ç¤º
            for d in dir_group:
                result[d] = [d]
        else:
            # å¦‚æœç»„å†…ç›®å½•å¾ˆå¤šï¼Œé€‰æ‹©å‰å‡ ä¸ªä½œä¸ºä»£è¡¨
            sorted_dirs = sorted(dir_group)
            representative = sorted_dirs[0]  # é€‰æ‹©ç¬¬ä¸€ä¸ªä½œä¸ºä»£è¡¨
            result[representative] = sorted_dirs  # åŒ…å«æ‰€æœ‰åŒç±»ç›®å½•
    
    return result

def analyze_directory(path, max_files_per_type=3, max_dirs_per_type=3, max_depth=6, current_depth=0):
    """åˆ†æç›®å½•ç»“æ„å¹¶ç”Ÿæˆç®€åŒ–çš„æ ‘å½¢æ˜¾ç¤º"""
    result = []
    
    if current_depth >= max_depth:
        return ["ğŸ“ ... (ç›®å½•å±‚çº§è¿‡æ·±ï¼Œå·²çœç•¥)"]
    
    try:
        items = os.listdir(path)
    except PermissionError:
        return ["âŒ (æƒé™ä¸è¶³ï¼Œæ— æ³•è®¿é—®)"]
    except Exception as e:
        return [f"âŒ (é”™è¯¯: {str(e)})"]
    
    # æŸ¥æ‰¾ç›¸ä¼¼ç›®å½•å¹¶åˆ†ç»„
    similar_dirs = find_similar_directories(path, max_dirs_per_type)
    
    # å¤„ç†ç›®å½•
    for representative, all_dirs in similar_dirs.items():
        dir_path = os.path.join(path, representative)
        
        if len(all_dirs) == 1:
            # å•ç‹¬çš„ç›®å½•
            result.append(f"ğŸ“ **{representative}/**")
            sub_items = analyze_directory(dir_path, max_files_per_type, max_dirs_per_type, max_depth, current_depth + 1)
            for item in sub_items:
                result.append(f"    {item}")
        else:
            # ç›¸ä¼¼ç›®å½•ç»„
            total_count = len(all_dirs)
            shown_count = min(max_dirs_per_type, total_count)
            
            # æ˜¾ç¤ºä»£è¡¨ç›®å½•çš„è¯¦ç»†ç»“æ„
            result.append(f"ğŸ“ **{representative}/** (ä»£è¡¨ {total_count} ä¸ªç›¸ä¼¼ç›®å½•)")
            sub_items = analyze_directory(dir_path, max_files_per_type, max_dirs_per_type, max_depth, current_depth + 1)
            for item in sub_items:
                result.append(f"    {item}")
            
            # æ˜¾ç¤ºå…¶ä»–å‡ ä¸ªåŒç±»ç›®å½•åç§°
            if shown_count > 1:
                other_dirs = sorted(all_dirs)[1:shown_count]
                for other_dir in other_dirs:
                    result.append(f"ğŸ“ **{other_dir}/** (ç»“æ„ç›¸ä¼¼)")
            
            # çœç•¥ä¿¡æ¯
            if total_count > shown_count:
                omitted = total_count - shown_count
                dir_range = f"ä» {min(all_dirs)} åˆ° {max(all_dirs)}" if len(set(all_dirs)) > 2 else "ç­‰"
                result.append(f"ğŸ“ ... *è¿˜æœ‰ {omitted} ä¸ªç»“æ„ç›¸ä¼¼çš„ç›®å½•* ({dir_range})")
    
    # å¤„ç†æ–‡ä»¶
    files = []
    for item in items:
        item_path = os.path.join(path, item)
        if os.path.isfile(item_path):
            files.append(item)
    
    if files:
        # æŒ‰æ‰©å±•ååˆ†ç»„æ–‡ä»¶
        files_by_ext = defaultdict(list)
        for file in files:
            ext = get_file_extension(file)
            try:
                size = os.path.getsize(os.path.join(path, file))
                files_by_ext[ext].append((file, size))
            except:
                files_by_ext[ext].append((file, 0))
        
        # æ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯
        for ext in sorted(files_by_ext.keys()):
            file_list = files_by_ext[ext]
            total_count = len(file_list)
            
            if ext == '':
                ext_display = "**æ— æ‰©å±•åæ–‡ä»¶**"
            else:
                ext_display = f"**{ext} æ–‡ä»¶**"
            
            if total_count <= max_files_per_type:
                # æ˜¾ç¤ºæ‰€æœ‰æ–‡ä»¶
                result.append(f"ğŸ“„ {ext_display} ({total_count} ä¸ª):")
                for filename, size in file_list:
                    size_str = get_file_size_str(size)
                    result.append(f"    - `{filename}` ({size_str})")
            else:
                # åªæ˜¾ç¤ºå‰å‡ ä¸ªæ–‡ä»¶ï¼Œå…¶ä½™çœç•¥
                result.append(f"ğŸ“„ {ext_display} ({total_count} ä¸ª):")
                for filename, size in file_list[:max_files_per_type]:
                    size_str = get_file_size_str(size)
                    result.append(f"    - `{filename}` ({size_str})")
                
                remaining = total_count - max_files_per_type
                total_size = sum(size for _, size in file_list)
                total_size_str = get_file_size_str(total_size)
                result.append(f"    - ... *è¿˜æœ‰ {remaining} ä¸ªåŒç±»å‹æ–‡ä»¶* (æ€»è®¡: {total_size_str})")
    
    return result

def generate_directory_report(target_path, output_file):
    """ç”Ÿæˆç›®å½•æŠ¥å‘Šå¹¶å†™å…¥æ–‡ä»¶"""
    if not os.path.exists(target_path):
        print(f"âŒ **é”™è¯¯**: è·¯å¾„ä¸å­˜åœ¨: `{target_path}`")
        return
    
    if not os.path.isdir(target_path):
        print(f"âŒ **é”™è¯¯**: ä¸æ˜¯ç›®å½•: `{target_path}`")
        return
    
    # å‡†å¤‡è¾“å‡ºå†…å®¹
    output_lines = []
    
    output_lines.append("# ğŸ“ ç›®å½•ç»“æ„åˆ†ææŠ¥å‘Š\\n")
    output_lines.append(f"**è·¯å¾„**: `{target_path}`\\n")
    output_lines.append(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n")
    
    # è·å–ç›®å½•æ€»ä½“ä¿¡æ¯
    total_size = 0
    total_files = 0
    total_dirs = 0
    
    for root, dirs, files in os.walk(target_path):
        total_dirs += len(dirs)
        total_files += len(files)
        for file in files:
            try:
                total_size += os.path.getsize(os.path.join(root, file))
            except:
                pass
    
    output_lines.append("**æ¦‚è§ˆä¿¡æ¯**:")
    output_lines.append(f"- ğŸ“ æ€»ç›®å½•æ•°: {total_dirs}")
    output_lines.append(f"- ğŸ“„ æ€»æ–‡ä»¶æ•°: {total_files}")
    output_lines.append(f"- ğŸ’¾ æ€»å¤§å°: {get_file_size_str(total_size)}\\n")
    
    output_lines.append("---\\n")
    output_lines.append("## ğŸ“‹ è¯¦ç»†ç»“æ„\\n")
    
    # ç”Ÿæˆè¯¦ç»†ç»“æ„
    tree_lines = analyze_directory(target_path)
    output_lines.extend(tree_lines)
    
    output_lines.append("\\n---")
    output_lines.append("\\n**ğŸ“ è¯´æ˜**:")
    output_lines.append("- ä¸ºäº†ä¿æŒè¾“å‡ºç®€æ´ï¼Œ**æ¯ç§æ–‡ä»¶ç±»å‹æœ€å¤šæ˜¾ç¤º 3 ä¸ªç¤ºä¾‹**")
    output_lines.append("- **å¤§é‡åŒç±»å‹æ–‡ä»¶ä¼šè¢«çœç•¥æ˜¾ç¤º**ï¼Œä½†ä¼šæ˜¾ç¤ºæ€»æ•°å’Œæ€»å¤§å°")
    output_lines.append("- **ç›¸ä¼¼ç»“æ„çš„ç›®å½•ä¼šè¢«åˆ†ç»„æ˜¾ç¤º**ï¼Œé¿å…é‡å¤å†—ä½™ä¿¡æ¯")
    output_lines.append("- **ç›®å½•å±‚çº§é™åˆ¶ä¸º 6 å±‚**ï¼Œé¿å…è¿‡æ·±çš„åµŒå¥—")
    output_lines.append("- **æ–‡ä»¶å¤§å°**ä¼šè‡ªåŠ¨è½¬æ¢ä¸ºåˆé€‚çš„å•ä½æ˜¾ç¤º")
    
    # å†™å…¥æ–‡ä»¶
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            for line in output_lines:
                f.write(line + '\\n')
        
        print("âœ… **æŠ¥å‘Šç”Ÿæˆå®Œæˆ**!")
        print(f"ğŸ“„ **æ–‡ä»¶ä½ç½®**: `{os.path.abspath(output_file)}`")
        print(f"ğŸ“Š **æŠ¥å‘Šè¡Œæ•°**: {len(output_lines)} è¡Œ")
        
    except Exception as e:
        print(f"âŒ **å†™å…¥æ–‡ä»¶å¤±è´¥**: {str(e)}")

# ä¸»ç¨‹åº
if __name__ == "__main__":
    import os
    target_directory = os.getenv('TARGET_DIR', './')
    output_filename = os.getenv('OUTPUT_FILE', 'directory_report.md')
    generate_directory_report(target_directory, output_filename)

EOF

'''

os.system(shell_code)


class ProjectDocumentGenerator:
    def __init__(self, project_root=None):
        """åˆå§‹åŒ–æ–‡æ¡£ç”Ÿæˆå™¨"""
        self.project_root = './'
        self.output_file = os.path.join(self.project_root, f"./æ–‡æ¡£/project_documentation_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md")
        
        # å®šä¹‰è¦å¿½ç•¥çš„ç›®å½•å’Œæ–‡ä»¶
        self.ignore_dirs = {
            '__pycache__', '.git', '.idea', '.vscode', 'venv', 'env', 
            'uploads', 'outputs', '.pytest_cache', 'node_modules','claudè¾“å‡º','project_documentation'
        }
        self.ignore_files = {
            '.pyc', '.pyo', '.DS_Store', '.gitignore', '.env', 
            '__pycache__', '.log', '.db', '.sqlite', '.npy', '.pkl',
            'project_documentation_','generate_project_docs'#,'directory_report'
        }
        
        # å®šä¹‰è¦åŒ…å«çš„æ–‡ä»¶æ‰©å±•å
        self.include_extensions = {
            '.py', '.json'#'.js', '.txt', '.md',
            #'.yaml', '.yml', '.sh', '.bat', '.sql','.cfg','project_documentation' # '.html',  '.css',   '.json',  '.ini', 
        }

        self.include_files = {
            'directory_report.md'
        }
        
        # é¡¹ç›®ç»“æ„
        self.tree_structure = []
        self.file_contents = []
        
    def should_include_file(self, file_path):
        """åˆ¤æ–­æ–‡ä»¶æ˜¯å¦åº”è¯¥åŒ…å«åœ¨æ–‡æ¡£ä¸­"""
        file_name = os.path.basename(file_path)
        file_ext = os.path.splitext(file_path)[1].lower()
        
        for include_file in self.include_files :
            if include_file in file_name:
                return True

        # æ£€æŸ¥æ˜¯å¦æ˜¯è¦å¿½ç•¥çš„æ–‡ä»¶
        for ignore_pattern in self.ignore_files:
            if ignore_pattern in file_name:
                return False
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯è¦åŒ…å«çš„æ‰©å±•å
        if self.include_extensions and file_ext not in self.include_extensions:
            return False
        
        # å¿½ç•¥è¿‡å¤§çš„æ–‡ä»¶ï¼ˆå¤§äº1MBï¼‰
        try:
            if os.path.getsize(file_path) > 1024 * 1024:
                return False
        except:
            return False
        
        return True
    
    def get_language_for_file(self, file_path):
        """æ ¹æ®æ–‡ä»¶æ‰©å±•åè¿”å›ä»£ç å—è¯­è¨€æ ‡è¯†"""
        ext = os.path.splitext(file_path)[1].lower()
        language_map = {
            '.py': 'python',
            '.js': 'javascript',
            '.html': 'html',
            '.css': 'css',
            '.json': 'json',
            '.yaml': 'yaml',
            '.yml': 'yaml',
            '.sh': 'bash',
            '.bat': 'batch',
            '.sql': 'sql',
            '.md': 'markdown',
            '.txt': 'text',
            '.ini': 'ini',
            '.cfg': 'ini'
        }
        return language_map.get(ext, 'text')
    
    def generate_tree_structure(self, start_path, prefix="", is_last=True):
        """ç”Ÿæˆç›®å½•æ ‘ç»“æ„"""
        def get_sorted_items(path):
            """è·å–æ’åºåçš„ç›®å½•å’Œæ–‡ä»¶åˆ—è¡¨"""
            items = []
            try:
                for item in os.listdir(path):
                    if item.startswith('.') and item != '.env':
                        continue
                    item_path = os.path.join(path, item)
                    items.append((item, item_path, os.path.isdir(item_path)))
                # å…ˆæŒ‰æ˜¯å¦ä¸ºç›®å½•æ’åºï¼ˆç›®å½•åœ¨å‰ï¼‰ï¼Œç„¶åæŒ‰åç§°æ’åº
                items.sort(key=lambda x: (not x[2], x[0].lower()))
            except PermissionError:
                pass
            return items
        
        # æ·»åŠ å½“å‰ç›®å½•
        current_dir = os.path.basename(start_path)
        if current_dir:
            connector = "â””â”€â”€ " if is_last else "â”œâ”€â”€ "
            self.tree_structure.append(f"{prefix}{connector}{current_dir}/")
            extension = "    " if is_last else "â”‚   "
            new_prefix = prefix + extension
        else:
            new_prefix = prefix
        
        # è·å–å¹¶å¤„ç†å­é¡¹
        items = get_sorted_items(start_path)
        for index, (name, path, is_dir) in enumerate(items):
            is_last_item = index == len(items) - 1
            
            if is_dir:
                if name not in self.ignore_dirs:
                    self.generate_tree_structure(path, new_prefix, is_last_item)
            else:
                if self.should_include_file(path):
                    connector = "â””â”€â”€ " if is_last_item else "â”œâ”€â”€ "
                    self.tree_structure.append(f"{new_prefix}{connector}{name}")
    
    def collect_file_contents(self, start_path):
        """é€’å½’æ”¶é›†æ‰€æœ‰æ–‡ä»¶å†…å®¹"""
        for root, dirs, files in os.walk(start_path):
            # è¿‡æ»¤æ‰è¦å¿½ç•¥çš„ç›®å½•
            dirs[:] = [d for d in dirs if d not in self.ignore_dirs]
            
            # è·å–ç›¸å¯¹è·¯å¾„
            rel_path = os.path.relpath(root, self.project_root)
            
            for file in sorted(files):
                file_path = os.path.join(root, file)
                if self.should_include_file(file_path):
                    self.read_and_store_file(file_path, rel_path)
    
    def read_and_store_file(self, file_path, rel_path):
        """è¯»å–å¹¶å­˜å‚¨æ–‡ä»¶å†…å®¹"""
        try:
            # å°è¯•ä½¿ç”¨UTF-8ç¼–ç è¯»å–
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # è·å–å®Œæ•´ç›¸å¯¹è·¯å¾„
            if rel_path == '.':
                full_rel_path = os.path.basename(file_path)
            else:
                full_rel_path = os.path.join(rel_path, os.path.basename(file_path))
            
            # è·å–ä»£ç è¯­è¨€
            language = self.get_language_for_file(file_path)
            
            self.file_contents.append({
                'path': full_rel_path,
                'absolute_path': file_path,
                'language': language,
                'content': content
            })
            
        except Exception as e:
            print(f"è­¦å‘Š: æ— æ³•è¯»å–æ–‡ä»¶ {file_path}: {str(e)}")
    
    def generate_markdown(self):
        """ç”ŸæˆMarkdownæ–‡æ¡£"""
        markdown_content = []
        
        # æ ‡é¢˜å’ŒåŸºæœ¬ä¿¡æ¯
        markdown_content.append("# é¡¹ç›®ä»£ç æ–‡æ¡£\n")
        markdown_content.append(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        markdown_content.append(f"**é¡¹ç›®è·¯å¾„**: `{self.project_root}`\n")
        markdown_content.append("\n---\n")
        
        # ç›®å½•
        markdown_content.append("## ç›®å½•\n")
        markdown_content.append("1. [é¡¹ç›®ç»“æ„](#é¡¹ç›®ç»“æ„)")
        markdown_content.append("2. [ä»£ç æ–‡ä»¶å†…å®¹](#ä»£ç æ–‡ä»¶å†…å®¹)")
        for i, file_info in enumerate(self.file_contents, 1):
            file_name = os.path.basename(file_info['path'])
            anchor = file_info['path'].replace('/', '-').replace('\\', '-').replace('.', '-').replace(' ', '-').lower()
            markdown_content.append(f"   - [{file_info['path']}](#{anchor})")
        markdown_content.append("\n---\n")
        
        # é¡¹ç›®ç»“æ„
        markdown_content.append("## é¡¹ç›®ç»“æ„\n")
        markdown_content.append("```")
        markdown_content.append(self.project_root + "/")
        markdown_content.extend(self.tree_structure)
        markdown_content.append("```\n")
        markdown_content.append("\n---\n")
        
        # ä»£ç æ–‡ä»¶å†…å®¹
        markdown_content.append("## ä»£ç æ–‡ä»¶å†…å®¹\n")
        
        for file_info in self.file_contents:
            # åˆ›å»ºé”šç‚¹
            anchor = file_info['path'].replace('/', '-').replace('\\', '-').replace('.', '-').replace(' ', '-').lower()
            
            # æ–‡ä»¶æ ‡é¢˜
            markdown_content.append(f"### {file_info['path']} {{#{anchor}}}\n")
            markdown_content.append(f"**å®Œæ•´è·¯å¾„**: `{file_info['absolute_path']}`\n")
            markdown_content.append(f"**æ–‡ä»¶å†…å®¹**:\n")
            markdown_content.append(f"```{file_info['language']}")
            markdown_content.append(file_info['content'])
            if not file_info['content'].endswith('\n'):
                markdown_content.append('')
            markdown_content.append("```\n")
            markdown_content.append("\n---\n")
        
        # æ·»åŠ ä½¿ç”¨è¯´æ˜
        markdown_content.append("## ä½¿ç”¨è¯´æ˜\n")
        markdown_content.append("æ­¤æ–‡æ¡£ç”±è‡ªåŠ¨åŒ–è„šæœ¬ç”Ÿæˆï¼ŒåŒ…å«äº†é¡¹ç›®çš„å®Œæ•´ç»“æ„å’Œæ‰€æœ‰ä»£ç æ–‡ä»¶å†…å®¹ã€‚\n")
        markdown_content.append("æ‚¨å¯ä»¥å°†æ­¤æ–‡æ¡£æä¾›ç»™AIåŠ©æ‰‹æˆ–å…¶ä»–å¼€å‘è€…ï¼Œä»¥ä¾¿ä»–ä»¬äº†è§£é¡¹ç›®çš„å®Œæ•´æƒ…å†µã€‚\n")
        markdown_content.append("\n### æ³¨æ„äº‹é¡¹ï¼š\n")
        markdown_content.append("- äºŒè¿›åˆ¶æ–‡ä»¶ã€ç¼“å­˜æ–‡ä»¶å’Œå¤§æ–‡ä»¶å·²è¢«è‡ªåŠ¨è¿‡æ»¤")
        markdown_content.append("- æ•æ„Ÿä¿¡æ¯ï¼ˆå¦‚å¯†ç ã€å¯†é’¥ï¼‰è¯·åœ¨åˆ†äº«å‰æ‰‹åŠ¨æ£€æŸ¥å¹¶åˆ é™¤")
        markdown_content.append("- ç”Ÿæˆçš„æ–‡æ¡£å¯èƒ½è¾ƒå¤§ï¼Œå»ºè®®ä½¿ç”¨æ”¯æŒå¤§æ–‡ä»¶çš„ç¼–è¾‘å™¨æ‰“å¼€\n")
        
        return '\n'.join(markdown_content)
    
    def generate(self):
        """æ‰§è¡Œæ–‡æ¡£ç”Ÿæˆ"""
        print(f"å¼€å§‹ç”Ÿæˆé¡¹ç›®æ–‡æ¡£...")
        print(f"é¡¹ç›®æ ¹ç›®å½•: {self.project_root}")
        
        # ç”Ÿæˆç›®å½•æ ‘
        print("æ­£åœ¨ç”Ÿæˆé¡¹ç›®ç»“æ„...")
        self.generate_tree_structure(self.project_root)
        
        # æ”¶é›†æ–‡ä»¶å†…å®¹
        print("æ­£åœ¨æ”¶é›†æ–‡ä»¶å†…å®¹...")
        self.collect_file_contents(self.project_root)
        
        # ç”ŸæˆMarkdown
        print("æ­£åœ¨ç”ŸæˆMarkdownæ–‡æ¡£...")
        markdown_content = self.generate_markdown()
        
        # å†™å…¥æ–‡ä»¶
        try:
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(self.output_file), exist_ok=True)
            
            with open(self.output_file, 'w', encoding='utf-8') as f:
                f.write(markdown_content)
            
            # è®¡ç®—æ–‡æ¡£ç»Ÿè®¡ä¿¡æ¯
            doc_size = os.path.getsize(self.output_file) / 1024  # KB
            
            print(f"\nâœ… æ–‡æ¡£ç”ŸæˆæˆåŠŸ!")
            print(f"è¾“å‡ºæ–‡ä»¶: {self.output_file}")
            print(f"æ–‡æ¡£å¤§å°: {doc_size:.2f} KB")
            print(f"åŒ…å«æ–‡ä»¶æ•°: {len(self.file_contents)}")
            print(f"\næ‚¨ç°åœ¨å¯ä»¥å°†ç”Ÿæˆçš„Markdownæ–‡æ¡£å‘é€ç»™AIåŠ©æ‰‹æˆ–å…¶ä»–å¼€å‘è€…ã€‚")
            
            return self.output_file
            
        except Exception as e:
            print(f"\nâŒ æ–‡æ¡£ç”Ÿæˆå¤±è´¥: {str(e)}")
            return None

def main():
    """ä¸»å‡½æ•°"""
    # å¯ä»¥é€šè¿‡å‘½ä»¤è¡Œå‚æ•°æŒ‡å®šé¡¹ç›®è·¯å¾„
    if len(sys.argv) > 1:
        project_path = sys.argv[1]
    else:
        project_path = None
    
    # åˆ›å»ºæ–‡æ¡£ç”Ÿæˆå™¨
    generator = ProjectDocumentGenerator(project_path)
    
    # ç”Ÿæˆæ–‡æ¡£
    output_file = generator.generate()

if __name__ == "__main__":
    main()   # python generate_project_docs.py

